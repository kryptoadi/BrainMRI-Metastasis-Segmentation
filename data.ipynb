{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 images and 23 masks.\n",
      "Training set: (18, 256, 256, 1), Test set: (5, 256, 256, 1)\n",
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - dice_coefficient: 0.0203 - loss: 0.6836 - val_dice_coefficient: 2.7127e-04 - val_loss: 0.6614\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0288 - loss: 0.6383 - val_dice_coefficient: 2.3108e-04 - val_loss: 0.5590\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0178 - loss: 0.4827 - val_dice_coefficient: 6.1407e-05 - val_loss: 0.2812\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 0.0027 - loss: 0.2251 - val_dice_coefficient: 5.7712e-08 - val_loss: 0.0675\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 1.8288e-05 - loss: 0.2474 - val_dice_coefficient: 3.2915e-09 - val_loss: 0.0304\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 6.4328e-06 - loss: 0.2232 - val_dice_coefficient: 1.1879e-07 - val_loss: 0.0388\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - dice_coefficient: 6.4900e-05 - loss: 0.1346 - val_dice_coefficient: 4.1897e-06 - val_loss: 0.0616\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 7.3314e-04 - loss: 0.1301 - val_dice_coefficient: 2.1004e-05 - val_loss: 0.0653\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 0.0015 - loss: 0.1050 - val_dice_coefficient: 3.8702e-05 - val_loss: 0.0384\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - dice_coefficient: 0.0023 - loss: 0.1058 - val_dice_coefficient: 8.8151e-05 - val_loss: 0.0178\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 0.0059 - loss: 0.0747 - val_dice_coefficient: 3.3910e-04 - val_loss: 0.0191\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0144 - loss: 0.0582 - val_dice_coefficient: 7.9211e-04 - val_loss: 0.0128\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0251 - loss: 0.0647 - val_dice_coefficient: 0.0017 - val_loss: 0.0049\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - dice_coefficient: 0.0355 - loss: 0.0746 - val_dice_coefficient: 0.0020 - val_loss: 0.0097\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0318 - loss: 0.0360 - val_dice_coefficient: 0.0024 - val_loss: 0.0072\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - dice_coefficient: 0.0376 - loss: 0.0446 - val_dice_coefficient: 0.0018 - val_loss: 0.0176\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - dice_coefficient: 0.0619 - loss: 0.0616 - val_dice_coefficient: 0.0023 - val_loss: 0.0031\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - dice_coefficient: 0.0231 - loss: 0.0598 - val_dice_coefficient: 0.0025 - val_loss: 0.0078\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - dice_coefficient: 0.0779 - loss: 0.0541 - val_dice_coefficient: 0.0024 - val_loss: 0.0123\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0843 - loss: 0.0451 - val_dice_coefficient: 0.0031 - val_loss: 0.0037\n",
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - dice_coefficient: 0.0263 - loss: 0.6813 - val_dice_coefficient: 2.6440e-04 - val_loss: 0.6440\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - dice_coefficient: 0.0270 - loss: 0.6028 - val_dice_coefficient: 1.7097e-04 - val_loss: 0.4603\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0098 - loss: 0.3618 - val_dice_coefficient: 2.8657e-06 - val_loss: 0.1622\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 4.2927e-04 - loss: 0.2100 - val_dice_coefficient: 1.5552e-09 - val_loss: 0.0474\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 9.6855e-06 - loss: 0.2284 - val_dice_coefficient: 9.2766e-08 - val_loss: 0.0635\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 1.6252e-04 - loss: 0.1905 - val_dice_coefficient: 5.4815e-06 - val_loss: 0.1035\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0011 - loss: 0.1747 - val_dice_coefficient: 1.1828e-05 - val_loss: 0.0873\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - dice_coefficient: 9.2436e-04 - loss: 0.1356 - val_dice_coefficient: 7.0901e-06 - val_loss: 0.0385\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 8.9319e-04 - loss: 0.1540 - val_dice_coefficient: 2.9091e-05 - val_loss: 0.0276\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 0.0026 - loss: 0.1104 - val_dice_coefficient: 1.3043e-04 - val_loss: 0.0222\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - dice_coefficient: 0.0078 - loss: 0.0897 - val_dice_coefficient: 3.6166e-04 - val_loss: 0.0133\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - dice_coefficient: 0.0141 - loss: 0.0804 - val_dice_coefficient: 8.2027e-04 - val_loss: 0.0081\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 0.0209 - loss: 0.0618 - val_dice_coefficient: 0.0013 - val_loss: 0.0095\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - dice_coefficient: 0.0358 - loss: 0.0608 - val_dice_coefficient: 0.0017 - val_loss: 0.0090\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 0.0517 - loss: 0.0597 - val_dice_coefficient: 0.0020 - val_loss: 0.0045\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0484 - loss: 0.0597 - val_dice_coefficient: 0.0021 - val_loss: 0.0119\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0689 - loss: 0.0592 - val_dice_coefficient: 0.0025 - val_loss: 0.0037\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0662 - loss: 0.0483 - val_dice_coefficient: 0.0025 - val_loss: 0.0098\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0781 - loss: 0.0588 - val_dice_coefficient: 0.0026 - val_loss: 0.0064\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - dice_coefficient: 0.0632 - loss: 0.0547 - val_dice_coefficient: 0.0026 - val_loss: 0.0058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753ms/step - dice_coefficient: 0.0047 - loss: 0.0037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750ms/step - dice_coefficient: 0.0038 - loss: 0.0058\n",
      "Nested U-Net Evaluation: [0.0037191002629697323, 0.004663208965212107]\n",
      "Attention U-Net Evaluation: [0.005793236196041107, 0.003807942382991314]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define paths to your images and masks (change these to your actual paths)\n",
    "image_dir = r'C:\\Users\\krraj\\OneDrive\\Desktop\\5C\\Data\\TCGA_CS_4941_19960909\\images'\n",
    "mask_dir = r'C:\\Users\\krraj\\OneDrive\\Desktop\\5C\\Data\\TCGA_CS_4941_19960909\\masks'\n",
    "\n",
    "# 1. Function to load all MRI images\n",
    "def load_images(image_dir):\n",
    "    images = []\n",
    "    for img_file in glob.glob(os.path.join(image_dir, '*.tif')):  \n",
    "        img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (256, 256))  # Resize if needed (optional)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# 2. Function to load all corresponding masks\n",
    "def load_masks(mask_dir):\n",
    "    masks = []\n",
    "    for mask_file in glob.glob(os.path.join(mask_dir, '*.tif')):  \n",
    "        mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)  # Load mask in grayscale\n",
    "        if mask is not None:\n",
    "            mask = cv2.resize(mask, (256, 256))  # Resize if needed (optional)\n",
    "            masks.append(mask)\n",
    "    return np.array(masks)\n",
    "\n",
    "# Load images and masks\n",
    "images = load_images(image_dir)\n",
    "masks = load_masks(mask_dir)\n",
    "\n",
    "print(f'Loaded {len(images)} images and {len(masks)} masks.')\n",
    "\n",
    "# 3. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) on images\n",
    "def apply_clahe(images):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        clahe_img = clahe.apply(img)  # Apply CLAHE to each image\n",
    "        processed_images.append(clahe_img)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Apply CLAHE to images\n",
    "images_clahe = apply_clahe(images)\n",
    "\n",
    "# 4. Normalize both images and masks\n",
    "def normalize_images(images):\n",
    "    return images / 255.0  # Normalize pixel values to range [0, 1]\n",
    "\n",
    "images_norm = normalize_images(images_clahe)\n",
    "masks_norm = normalize_images(masks)\n",
    "\n",
    "# 5. Reshape the data to match the model input shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_norm, masks_norm, test_size=0.2, random_state=42)\n",
    "X_train = X_train[..., np.newaxis]  # Shape: (batch_size, 256, 256, 1)\n",
    "X_test = X_test[..., np.newaxis]    # Shape: (batch_size, 256, 256, 1)\n",
    "y_train = y_train[..., np.newaxis]  # Shape: (batch_size, 256, 256, 1)\n",
    "y_test = y_test[..., np.newaxis]    # Shape: (batch_size, 256, 256, 1)\n",
    "\n",
    "print(f'Training set: {X_train.shape}, Test set: {X_test.shape}')\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "# 7. Define a simple U-Net model (can be replaced with Nested U-Net or Attention U-Net)\n",
    "def build_unet_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    merge4 = concatenate([conv2, up4], axis=3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    merge5 = concatenate([conv1, up5], axis=3)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build models (Nested U-Net and Attention U-Net can be defined similarly)\n",
    "nested_unet_model = build_unet_model((256, 256, 1))\n",
    "attention_unet_model = build_unet_model((256, 256, 1))  # Placeholder for Attention U-Net\n",
    "\n",
    "# 8. Compile the models\n",
    "nested_unet_model.compile(optimizer=Adam(learning_rate=1e-4), loss=BinaryCrossentropy(), metrics=[dice_coefficient])\n",
    "attention_unet_model.compile(optimizer=Adam(learning_rate=1e-4), loss=BinaryCrossentropy(), metrics=[dice_coefficient])\n",
    "\n",
    "\n",
    "# 9. Train the models\n",
    "history_nested_unet = nested_unet_model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test))\n",
    "history_attention_unet = attention_unet_model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test))\n",
    "\n",
    "# 10. Evaluate the models\n",
    "nested_unet_eval = nested_unet_model.evaluate(X_test, y_test)\n",
    "attention_unet_eval = attention_unet_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Nested U-Net Evaluation: {nested_unet_eval}\")\n",
    "print(f\"Attention U-Net Evaluation: {attention_unet_eval}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
