{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 images and 23 masks.\n",
      "Training set: (18, 256, 256, 1), Test set: (5, 256, 256, 1)\n",
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - dice_coefficient: 0.0203 - loss: 0.6836 - val_dice_coefficient: 2.7127e-04 - val_loss: 0.6614\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0288 - loss: 0.6383 - val_dice_coefficient: 2.3108e-04 - val_loss: 0.5590\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - dice_coefficient: 0.0178 - loss: 0.4827 - val_dice_coefficient: 6.1407e-05 - val_loss: 0.2812\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - dice_coefficient: 0.0027 - loss: 0.2251 - val_dice_coefficient: 5.7712e-08 - val_loss: 0.0675\n",
      "Epoch 5/20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define paths to your images and masks (change these to your actual paths)\n",
    "image_dir = r'C:\\Users\\krraj\\OneDrive\\Desktop\\5C\\Data\\TCGA_CS_4941_19960909\\images'\n",
    "mask_dir = r'C:\\Users\\krraj\\OneDrive\\Desktop\\5C\\Data\\TCGA_CS_4941_19960909\\masks'\n",
    "\n",
    "# 1. Function to load all MRI images\n",
    "def load_images(image_dir):\n",
    "    images = []\n",
    "    for img_file in glob.glob(os.path.join(image_dir, '*.tif')):  \n",
    "        img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (256, 256))  # Resize if needed (optional)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# 2. Function to load all corresponding masks\n",
    "def load_masks(mask_dir):\n",
    "    masks = []\n",
    "    for mask_file in glob.glob(os.path.join(mask_dir, '*.tif')):  \n",
    "        mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)  # Load mask in grayscale\n",
    "        if mask is not None:\n",
    "            mask = cv2.resize(mask, (256, 256))  # Resize if needed (optional)\n",
    "            masks.append(mask)\n",
    "    return np.array(masks)\n",
    "\n",
    "# Load images and masks\n",
    "images = load_images(image_dir)\n",
    "masks = load_masks(mask_dir)\n",
    "\n",
    "print(f'Loaded {len(images)} images and {len(masks)} masks.')\n",
    "\n",
    "# 3. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) on images\n",
    "def apply_clahe(images):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        clahe_img = clahe.apply(img)  # Apply CLAHE to each image\n",
    "        processed_images.append(clahe_img)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Apply CLAHE to images\n",
    "images_clahe = apply_clahe(images)\n",
    "\n",
    "# 4. Normalize both images and masks\n",
    "def normalize_images(images):\n",
    "    return images / 255.0  # Normalize pixel values to range [0, 1]\n",
    "\n",
    "images_norm = normalize_images(images_clahe)\n",
    "masks_norm = normalize_images(masks)\n",
    "\n",
    "# 5. Reshape the data to match the model input shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_norm, masks_norm, test_size=0.2, random_state=42)\n",
    "X_train = X_train[..., np.newaxis]  # Shape: (batch_size, 256, 256, 1)\n",
    "X_test = X_test[..., np.newaxis]    # Shape: (batch_size, 256, 256, 1)\n",
    "y_train = y_train[..., np.newaxis]  # Shape: (batch_size, 256, 256, 1)\n",
    "y_test = y_test[..., np.newaxis]    # Shape: (batch_size, 256, 256, 1)\n",
    "\n",
    "print(f'Training set: {X_train.shape}, Test set: {X_test.shape}')\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "# 7. Define a simple U-Net model (can be replaced with Nested U-Net or Attention U-Net)\n",
    "def build_unet_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    merge4 = concatenate([conv2, up4], axis=3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    merge5 = concatenate([conv1, up5], axis=3)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build models (Nested U-Net and Attention U-Net can be defined similarly)\n",
    "nested_unet_model = build_unet_model((256, 256, 1))\n",
    "attention_unet_model = build_unet_model((256, 256, 1))  # Placeholder for Attention U-Net\n",
    "\n",
    "# 8. Compile the models\n",
    "nested_unet_model.compile(optimizer=Adam(learning_rate=1e-4), loss=BinaryCrossentropy(), metrics=[dice_coefficient])\n",
    "attention_unet_model.compile(optimizer=Adam(learning_rate=1e-4), loss=BinaryCrossentropy(), metrics=[dice_coefficient])\n",
    "\n",
    "\n",
    "# 9. Train the models\n",
    "history_nested_unet = nested_unet_model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test))\n",
    "history_attention_unet = attention_unet_model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test))\n",
    "\n",
    "# 10. Evaluate the models\n",
    "nested_unet_eval = nested_unet_model.evaluate(X_test, y_test)\n",
    "attention_unet_eval = attention_unet_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Nested U-Net Evaluation: {nested_unet_eval}\")\n",
    "print(f\"Attention U-Net Evaluation: {attention_unet_eval}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
